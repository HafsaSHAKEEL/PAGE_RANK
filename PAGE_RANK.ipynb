{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "graph = {\n",
        "    'A': ['D','E','F'],\n",
        "    'B': ['A', 'F'],\n",
        "    'C': ['A', 'B','D'],\n",
        "    'D': [ 'C','B'],\n",
        "    'E': ['C','D','B','F'],\n",
        "    'F': ['A','B','D']\n",
        "}\n",
        "#This code implements the PageRank algorithm to calculate the importance of each node in a directed graph,\n",
        "#redistributing ranks iteratively based on incoming links until convergence or a maximum number of iterations is reached.\n",
        "# The damping factor adjusts the probability of continuing the random walk, and residuals measure the convergence criteria."
      ],
      "metadata": {
        "id": "6TG7nQOilWbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTDDRAnxZJib"
      },
      "outputs": [],
      "source": [
        "def pagerank(graph, maxiterations, dampingfactor=0.85, epsilon=1e-8):\n",
        "    numnodes = len(graph)\n",
        "    initialscore = 1.0 / numnodes\n",
        "    pageranks = dict((nodeid, initialscore) for nodeid in graph) # Initialize same initial score\n",
        "    outdegrees = dict((nodeid, len(outgoinglinks)) for nodeid, outgoinglinks in graph.items()) # Calculate the number of outgoing\n",
        "    incominglinks = dict((nodeid, set(incominglinks)) for nodeid, incominglinks in graph.items())\n",
        "    a = 0\n",
        "    while a < maxiterations:\n",
        "        oldpageranks = pageranks.copy() # Create a copy to compare later\n",
        "        sum_residuals = 0\n",
        "        lostpagerank = 0\n",
        "        for nodeid in graph.keys():\n",
        "            incomingpagerank = sum(oldpageranks[link] / outdegrees[link] for link in incominglinks[nodeid] if outdegrees[link] > 0) # Calculate the PageRan by looking at ncoming links\n",
        "            if outdegrees[nodeid] == 0:\n",
        "                lostpagerank += oldpageranks[nodeid] / numnodes # Accumulate the PageRank of sink nodes\n",
        "            pageranks[nodeid] = (1 - dampingfactor) / numnodes + dampingfactor * incomingpagerank # Calculate the new PageRank  for the current node\n",
        "            sum_residuals += abs(pageranks[nodeid] - oldpageranks[nodeid]) # Accumulate the differences between new and old PageRank scores\n",
        "        lostpagerank = dampingfactor * lostpagerank # Apply damping factor to the new lost PageRank\n",
        "        for nodeid in graph.keys():\n",
        "            pageranks[nodeid] += lostpagerank # Redistribute the lost PageRank equally among all nodes\n",
        "        if sum_residuals < epsilon: # Check if the PageRank scores have converged\n",
        "            break\n",
        "        a += 1\n",
        "\n",
        "    return pageranks\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iterations = 1\n",
        "pageranks = pagerank(graph, iterations)\n",
        "print(\" after 1 iteration,the values are:\")\n",
        "for node, score in pageranks.items():\n",
        "    print(f\"{node}: {score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thijxCZSA9FQ",
        "outputId": "de23adc5-b506-431d-8a91-138f199d571d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " after 1 iteration,the values are:\n",
            "A: 0.1784722222222222\n",
            "B: 0.11944444444444445\n",
            "C: 0.21388888888888888\n",
            "D: 0.14305555555555555\n",
            "E: 0.2611111111111111\n",
            "F: 0.21388888888888888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iterations = 10\n",
        "pageranks = pagerank(graph, iterations)\n",
        "print(\" after 10 iteration,the values are:\")\n",
        "for node, score in pageranks.items():\n",
        "    print(f\"{node}: {score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgu5AjgLA9NL",
        "outputId": "c55e8d68-64a8-409c-d8ed-c5660a561233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " after 10 iteration,the values are:\n",
            "A: 0.1921846512003636\n",
            "B: 0.13476368555686338\n",
            "C: 0.19519663002814236\n",
            "D: 0.1375817102570162\n",
            "E: 0.25135587617012867\n",
            "F: 0.19519663002814236\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iterations = 100\n",
        "pageranks = pagerank(graph, iterations)\n",
        "print(\" after 100 iteration,the values are:\")\n",
        "for node, score in pageranks.items():\n",
        "    print(f\"{node}: {score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN4VE2abA9Om",
        "outputId": "27b10153-282c-4608-ba00-a2b7b08d5e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " after 100 iteration,the values are:\n",
            "A: 0.19219066301767995\n",
            "B: 0.1347602063237994\n",
            "C: 0.1951983000414854\n",
            "D: 0.13757927332008815\n",
            "E: 0.2513566489119995\n",
            "F: 0.1951983000414854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PAART 2**"
      ],
      "metadata": {
        "id": "DsnSuFDAh-eO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import log\n",
        "import operator\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "kjykvmoLBWL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "file_path = 'a.txt'\n",
        "with open(file_path, 'r') as file:\n",
        "    l= file.readlines()\n",
        "DocumentIdPageRank = {}\n",
        "def calculateperplexity():\n",
        "    entropy = 0\n",
        "    for page in DocumentIdPageRank.keys():\n",
        "        entropy += DocumentIdPageRank[page]*log(1/DocumentIdPageRank[page],2)\n",
        "    return 2**entropy\n",
        "preplexity = []\n",
        "def calculateconvergence(j):\n",
        "    preplexvalue = calculateperplexity()\n",
        "    preplexity.append(preplexvalue)\n",
        "    if (len(preplexity)>4):# It compares the last 4 perplexity values, and if they are equal, it assumes convergence and prints the iteration and perplexity value.\n",
        "        if((int(preplexity[j]))==(int(preplexity[j-1]))==(int(preplexity[j-2]))==(int(preplexity[j-3]))):\n",
        "            print (j+1,calculateperplexity())\n",
        "            return False\n",
        "        else:\n",
        "            return True\n",
        "    else:\n",
        "        return True"
      ],
      "metadata": {
        "id": "3kNMfC5b-xdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DocumentIdInlinks={}\n",
        "DocumentId = []\n",
        "for line in l:\n",
        "    line = line.split()\n",
        "    DocumentIdInlinks[line[0]] = line[1:]\n",
        "    DocumentId.append(line[0])\n",
        "DocumentIdOutlinks = {}\n",
        "for i in DocumentId:\n",
        "    DocumentIdOutlinks[i] = 0\n",
        "for values in DocumentIdInlinks.values():\n",
        "    for value in values:\n",
        "            DocumentIdOutlinks[value] += 1\n",
        "SinkNodes = []\n",
        "for page in DocumentIdOutlinks.keys():\n",
        "    if DocumentIdOutlinks[page] == 0:\n",
        "        SinkNodes.append(page)\n",
        "N = float(len(DocumentId))\n",
        "for p in DocumentId:\n",
        "    DocumentIdPageRank[p] = 1.0/N\n",
        "print(\"PRINTING PERPLEXITY VALUES: 1\") # The lower the perplexity value, the closer the PageRank distribution is to a uniform distribution,\n",
        "#indicating that the algorithm IS converged.\n",
        "a = 0\n",
        "newPR = {}\n",
        "d = 0.85\n",
        "print(\"Perplexity Values:\")\n",
        "L = {}\n",
        "for values in DocumentIdInlinks.values():\n",
        "    for value in values:\n",
        "        if value not in L:\n",
        "            L[value] = 0\n",
        "        L[value] += 1\n",
        "while calculateconvergence(a):\n",
        "    print (a+1, calculateperplexity()  )\n",
        "    sinkPR = 0\n",
        "    for b in SinkNodes:\n",
        "        sinkPR += DocumentIdPageRank[b]\n",
        "    for b in DocumentId:\n",
        "        newPR[b] = (1.0 - d)/N\n",
        "        newPR[b] += d*sinkPR/N\n",
        "        for q in DocumentIdInlinks[p]:\n",
        "            newPR[b] += d*DocumentIdPageRank[q]/L[q]\n",
        "    for p in DocumentId:\n",
        "        DocumentIdPageRank[b] = newPR[b]\n",
        "    a = a+ 1\n",
        "SortedPR = sorted(DocumentIdPageRank.items(), key=operator.itemgetter(1), reverse=True)\n",
        "print(\"SORT THE COLLECTION OFWEBPAGES\")\n",
        "print(\"Top 10 pages as sorted by PageRank\")\n",
        "for i in range(10):\n",
        "    print (SortedPR[i] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2qMYQqD9lPD",
        "outputId": "1efbb378-6df6-4c30-9e33-6c1439423d41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PRINTING PERPLEXITY VALUES: 1\n",
            "Perplexity Values:\n",
            "1 183810.9999981843\n",
            "2 183804.76416618098\n",
            "3 183804.76416618098\n",
            "4 183804.76416618098\n",
            "5 183804.76416618098\n",
            "SORT THE COLLECTION OFWEBPAGES\n",
            "Top 10 pages as sorted by PageRank\n",
            "('WT01-B01-2', 5.4403708156747966e-06)\n",
            "('WT01-B01-3', 5.4403708156747966e-06)\n",
            "('WT01-B01-4', 5.4403708156747966e-06)\n",
            "('WT01-B01-11', 5.4403708156747966e-06)\n",
            "('WT01-B01-12', 5.4403708156747966e-06)\n",
            "('WT01-B01-13', 5.4403708156747966e-06)\n",
            "('WT01-B01-14', 5.4403708156747966e-06)\n",
            "('WT01-B01-17', 5.4403708156747966e-06)\n",
            "('WT01-B01-18', 5.4403708156747966e-06)\n",
            "('WT01-B01-19', 5.4403708156747966e-06)\n"
          ]
        }
      ]
    }
  ]
}